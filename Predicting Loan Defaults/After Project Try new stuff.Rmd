---
title: "DS705 Final Project - Predicting Loan Defaults"
author: "Pete Kelley"
date: "July 30, 2018"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE) # , eval=FALSE)

# load libraries
library(dplyr)

```

## Section 1 - Executive Summary (max 1 page)
To be completed in Part 3. 

## Section 2 - Introduction
This study uses a dataset of 30 variables across 50,000 loans to create a predictive model to help a bank identify which applicants are likely to default on their loans. The dataset was not ready to be evaluated and needed to be prepared for modeling. This paper will review data preparation, building and optimizing the model, and finally summarizing the results. 


## Section 3 - Preparing and Cleaning the Data

The following was done to prepare the data for processing:

•	Added a column for the response variable
  
  –	status column values of “Fully Paid” mapped to “Good”
  
  –	status column values of “Charged Off” mapped to “Bad”

•	Removed rows that did not fit the parameters for a valid response variable

  –	Valid response rows were those that had reached end of life and were either paid in full or written off; all other rows were deleted

•	Removed columns that we are unknowable at the time a loan was requested

  –	Grade of the loan application, which is a result of the loan application decision  process

  –	Status of the loan, this was mapped to the response variable

•	Kept but not used to create a model, only used to fine tune profitability.

  –	Rate of the loan, which is a result of the loan application decision process

  –	TotalPaid is not unknowable until the loan reaches end of life

•	Removed loadID column which contains that loan application ID
This left us with the following columns to explore and transform if needed:
 
```{r echo = FALSE}
# loan_data <- read.csv(file = 'E:/DataScience/UW_MSDS/!UW-705_Stats/Project/loans50k.csv')
loan_data <- read.csv(file = 'C:/Users/pete.kelley/Documents/DataScience/UW_MSDS/!UW-705_Stats/Project/loans50k.csv')
# Explore the data
# summary(loan_data)

# Add response var
loan_data$response <- NA
loan_data$response[loan_data$status=='Fully Paid']  <-  "Good"
loan_data$response[loan_data$status=='Charged Off']  <-  "Bad"
# make the charactor values of Good and Bad factors
loan_data$response <- as.factor(loan_data$response)
# remove records that are response values of NA (Any status other than Fully Paid or Charged Off)
trimmed_loan_data <- loan_data[!is.na(loan_data$response),] 

# Explore the data
# summary(trimmed_loan_data)

# LoanID is a row identifier and isn't representative of the applicant or loan
trimmed_loan_data$loanID <- NULL
# Rate is a result of the credit application process and not available at the time of application.
# trimmed_loan_data$rate <- NULL
# Grade is a result of the credit application process and not available at the time of application.
trimmed_loan_data$grade <- NULL
# Status has been mapped to the response variable. 
trimmed_loan_data$status <- NULL
# totalPaid can not be known at the time of application. 
# trimmed_loan_data$totalPaid <- NULL
colnames(trimmed_loan_data)

```


## Section 4 - Exploring and Transforming the Data


```{r include=FALSE, echo = FALSE}
#  amount
# summary(trimmed_loan_data$amount)
# boxplot(trimmed_loan_data$amount)
# Amount has no outliers and is ready for modeling. 
```




```{r include=FALSE, echo = FALSE}
trimmed_loan_data$term <- droplevels(trimmed_loan_data)$term
#  term
# summary(trimmed_loan_data$term)
# plot(trimmed_loan_data$term)
# Term has unused levels of factor that needed to be dropped but is now ready for modeling.
```




```{r include=FALSE, echo = FALSE}
#  payment
# summary(trimmed_loan_data$payment)
# boxplot(trimmed_loan_data$payment)
trimmed_loan_data$logPayment <- log10(trimmed_loan_data$payment)
# summary(trimmed_loan_data$logPayment)
# boxplot(trimmed_loan_data$logPayment)
# qqnorm(trimmed_loan_data$logPayment)
# qqline(trimmed_loan_data$logPayment)
# hist(trimmed_loan_data$logPayment)
trimmed_loan_data$payment <- NULL
# Payment has a strong skew to the right, a log base 10 transformation brought it back to closer to normal. The new column called logPayment. 
```

 

```{r include=FALSE, echo = FALSE}
#  employment
trimmed_loan_data$employment <- NULL

# Employment has 21k factors, way too many to be useful. I am going to delete this column on the bases that job title’s value might be in judging how stable a person's job prospects are and how much money they make, but doesn't do a good job for either.    
```

 
 

```{r include=FALSE, echo = FALSE }
#  length
# levels(trimmed_loan_data$length)
trimmed_loan_data$years <- NA
trimmed_loan_data$years[trimmed_loan_data$length==''] <- NA
trimmed_loan_data$years[trimmed_loan_data$length=='< 1 year'] <- 0.5
trimmed_loan_data$years[trimmed_loan_data$length=='1 year'] <- 1
trimmed_loan_data$years[trimmed_loan_data$length=='2 years'] <- 2
trimmed_loan_data$years[trimmed_loan_data$length=='3 years'] <- 3
trimmed_loan_data$years[trimmed_loan_data$length=='4 years'] <- 4
trimmed_loan_data$years[trimmed_loan_data$length=='5 years'] <- 5
trimmed_loan_data$years[trimmed_loan_data$length=='6 years'] <- 6
trimmed_loan_data$years[trimmed_loan_data$length=='7 years'] <- 7
trimmed_loan_data$years[trimmed_loan_data$length=='8 years'] <- 8
trimmed_loan_data$years[trimmed_loan_data$length=='9 years'] <- 9
trimmed_loan_data$years[trimmed_loan_data$length=='10+ years'] <- 10


summary(trimmed_loan_data$years)
# replace NA with mean for all datapoints
trimmed_loan_data$years[which(is.na(trimmed_loan_data$years))] <- mean(trimmed_loan_data$years,na.rm = TRUE)
# summary(trimmed_loan_data$length)
# table(trimmed_loan_data$years)
# We can remove length because it has been mapped to years.
trimmed_loan_data$length <- NULL
# Length of employment as discrete factors loses some of the information content of a continuous variable that order and magnitude have significance, I am turning the factors into dimensions.
summary(trimmed_loan_data$years)
# plot(trimmed_loan_data$years)
# boxplot(trimmed_loan_data$years)


```

 

```{r include=FALSE, echo = FALSE}
#  home
trimmed_loan_data$home <- droplevels(trimmed_loan_data$home)
# summary(trimmed_loan_data$home)
# plot(trimmed_loan_data$home)
# boxplot(trimmed_loan_data$home)
# Home had unused factor levels that needed to be dropped before it could be used.
```

 

```{r include=FALSE, echo = FALSE}
#  income
# summary(trimmed_loan_data$income)
# boxplot(trimmed_loan_data$income)
trimmed_loan_data$logIncome <- log10(trimmed_loan_data$income)
# summary(trimmed_loan_data$logIncome)
# boxplot(trimmed_loan_data$logIncome)
# qqnorm(trimmed_loan_data$logIncome)
# qqline(trimmed_loan_data$logIncome)
# hist(trimmed_loan_data$logIncome)
trimmed_loan_data$income <- NULL
# Income has a strong skew to the right, a log base 10 transformation brought it back to closer to normal. The new column called logIncome. 
```
 
 

```{r include=FALSE, echo = FALSE}
#  verified
# summary(trimmed_loan_data$verified)
trimmed_loan_data$verified <- droplevels(trimmed_loan_data$verified)
# plot(trimmed_loan_data$verified)
# Verified had unused factor levels that needed to be dropped before it could be used.
```



```{r include=FALSE, echo = FALSE}
# reason
# summary(trimmed_loan_data$reason)
trimmed_loan_data$reason[trimmed_loan_data$reason=='wedding'] <- 'other'
trimmed_loan_data$reason <- as.character(trimmed_loan_data$reason)
trimmed_loan_data$reason[is.na(trimmed_loan_data$reason)] <- 'other'
trimmed_loan_data$reason <- as.factor(trimmed_loan_data$reason)
trimmed_loan_data$reason <- droplevels(trimmed_loan_data$reason)
# summary(trimmed_loan_data$reason)
# Reason had unused levels of factor that needed to be dropped and I  combined wedding level (2 loans) with other, transformed the column to character to combine NAs (2 loans) with other and then transformed it back into a factor column before dropping unused factors. 
```

  
  

```{r include=FALSE, echo = FALSE}
#   state
# levels(trimmed_loan_data$state)
# temp <- summary(trimmed_loan_data$state)
# sort(temp)
# plot(trimmed_loan_data$state)
trimmed_loan_data$region <- setNames(state.region, state.abb)[trimmed_loan_data$state]
# factor(trimmed_loan_data$region)
# plot(trimmed_loan_data$region)
# State had several levels (states) with very low loan counts, so I have also added a region to the data and we will see if either of them are valuable.
# trimmed_loan_data$state <- NULL

```


```{r include=FALSE, echo = FALSE}
#  debtIncRat
# summary(trimmed_loan_data$debtIncRat)
# boxplot(trimmed_loan_data$debtIncRat)
# qqnorm(trimmed_loan_data$debtIncRat)
# qqline(trimmed_loan_data$debtIncRat)
#  debtIncRat has a few outliers, but the basic transformation made it worse, so I am leaving it the way it is. The spread isn’t large, and the outliers are not a significant portion of the dataset. 
```

 

```{r include=FALSE, echo = FALSE}
#  delinq2yr
# length(trimmed_loan_data$delinq2yr)
# length(trimmed_loan_data$delinq2yr[trimmed_loan_data$delinq2yr > 0])
# plot(trimmed_loan_data$delinq2yr)
# hist(trimmed_loan_data$delinq2yr[trimmed_loan_data$delinq2yr])
# boxplot(trimmed_loan_data$delinq2yr[trimmed_loan_data$delinq2yr])
# delinq2yr needs to be watched, the skew is significant with 80% of the data having a value of 0, and the rest ranging from 1 to 15. Because the spread is so small, a transformation will not do much to change the distribution shape.
```


```{r include=FALSE, echo = FALSE}
#  inq6mth
# summary(trimmed_loan_data$inq6mth)
# plot(trimmed_loan_data$inq6mth)
# boxplot(trimmed_loan_data$inq6mth)
# length(trimmed_loan_data$inq6mth)
# length(trimmed_loan_data$delinq2yr[trimmed_loan_data$inq6mth > 0])
# inq6mth needs to be watched, the skew is significant with 50% of the data having a value of 0, and the rest ranging from 1 to 6. Because the spread is so small, a transformation will not do much to change the distribution shape.

```



```{r include=FALSE, echo = FALSE}
#  openAcc
# summary(trimmed_loan_data$openAcc)
# plot(trimmed_loan_data$openAcc)
# boxplot(trimmed_loan_data$openAcc)
trimmed_loan_data$logOpenAcc <- log10(trimmed_loan_data$openAcc)
# qqnorm(trimmed_loan_data$logOpenAcc)
# qqline(trimmed_loan_data$logOpenAcc)
# summary(trimmed_loan_data$logOpenAcc)
# boxplot(trimmed_loan_data$logOpenAcc)
trimmed_loan_data$OpenAcc <- NULL
# openAcc has a strong skew to the right, a log base 10 transformation brought it back to closer to normal. The new column called logOpenAcc.
 
```


```{r include=FALSE, echo = FALSE}
#  pubRec
# summary(trimmed_loan_data$pubRec)
# plot(trimmed_loan_data$pubRec)
# length(trimmed_loan_data$pubRec)
# length(trimmed_loan_data$pubRec[trimmed_loan_data$pubRec > 0])
# pubRec needs to be watched, the skew is significant with 80% of the data having a value of 0, and the rest ranging from 1 to 19. Because the spread is so small, a transformation will not do much to change the distribution shape.
 

```


```{r include=FALSE, echo = FALSE}
#  revolRatio
# summary(trimmed_loan_data$revolRatio)
trimmed_loan_data$revolRatio[which(is.na(trimmed_loan_data$revolRatio))] <- mean(trimmed_loan_data$revolRatio, na.rm=TRUE)
# summary(trimmed_loan_data$revolRatio)
# plot(trimmed_loan_data$revolRatio)
# boxplot(trimmed_loan_data$revolRatio)
# revolRatio had 15 NA's that were replaced with the mean. Doesn’t need a transformation, small spread and only one indication of slight outliers.

```


```{r include=FALSE, echo = FALSE}
#  totalAcc
# summary(trimmed_loan_data$totalAcc)
# plot(trimmed_loan_data$totalAcc)
# boxplot(trimmed_loan_data$totalAcc)
# hist(trimmed_loan_data$totalAcc)
trimmed_loan_data$logTotalAcc <-  log10(trimmed_loan_data$totalAcc)
# boxplot(log10(trimmed_loan_data$logTotalAcc))
trimmed_loan_data$totalAcc <- NULL
# totalAcc has a strong skew to the right, a log base 10 transformation brought it back to closer to normal. The new column called logTotalAcc.

```


```{r include=FALSE, echo = FALSE}
#  totalBal
# summary(trimmed_loan_data$totalBal)
# plot(trimmed_loan_data$totalBal)
# boxplot(trimmed_loan_data$totalBal)
trimmed_loan_data$rootTotalBal <- (trimmed_loan_data$totalBal)^(1/6)
# summary(trimmed_loan_data$rootTotalBal)
# plot(trimmed_loan_data$rootTotalBal)
# boxplot(trimmed_loan_data$rootTotalBal)
trimmed_loan_data$rootTotalBal <- NULL

# totalBal has a strong right skew but we can't use log transformation because of negative infinity result, so used a 6th root because it balanced the upper and lower outliers best. The new column called rootTotalBal. 
```

 

```{r include=FALSE, echo = FALSE}
#  totalRevLim
# summary(trimmed_loan_data$totalRevLim)
# plot(trimmed_loan_data$totalRevLim)
# boxplot(trimmed_loan_data$totalRevLim)
trimmed_loan_data$rootTotalRevBal <- (trimmed_loan_data$totalRevBal)^(1/5) 
# summary(trimmed_loan_data$rootTotalRevBal)
# plot(trimmed_loan_data$rootTotalRevBal)
# boxplot(trimmed_loan_data$rootTotalRevBal)

trimmed_loan_data$totalRevBal <-  NULL

# totalRevLim has a strong right skew but we can't use log transformation because of negative infinity result, so used a 5th root because it balanced the upper and lower outliers best. The new column called rootTotalRevLim. 

```



```{r include=FALSE, echo = FALSE}
#  accOpen24
# summary(trimmed_loan_data$accOpen24)
# plot(trimmed_loan_data$accOpen24)
# boxplot(trimmed_loan_data$accOpen24)
trimmed_loan_data$rootaccOpen24 <- (trimmed_loan_data$accOpen24)^(1/2)
# summary(trimmed_loan_data$rootaccOpen24)
# plot(trimmed_loan_data$rootaccOpen24)
# boxplot(trimmed_loan_data$rootaccOpen24)
trimmed_loan_data$accOpen24 <-  NULL

# accOpen24 has a strong right skew but we can't use log transformation because of negative infinity result, so used a 2nd root because it balanced the upper and lower outliers best. The new column called root accOpen24. 

```



```{r include=FALSE, echo = FALSE}
#  avgBal
# summary(trimmed_loan_data$avgBal)
# plot(trimmed_loan_data$avgBal)
# boxplot(trimmed_loan_data$avgBal)
trimmed_loan_data$rootAvgBal <- (trimmed_loan_data$avgBal)^(1/5)
# summary(trimmed_loan_data$rootAvgBal)
# plot(trimmed_loan_data$rootAvgBal)
# boxplot(trimmed_loan_data$rootAvgBal)
trimmed_loan_data$AvgBal <-  NULL

#  avgBal has a strong right skew but we can't use log transformation because of negative infinity result, so used a 5th root because it balanced the upper and lower outliers best. The new column called rootavgBal. 
 
```


```{r include=FALSE, echo = FALSE}
#  bcOpen
summary(trimmed_loan_data$bcOpen)
# plot(trimmed_loan_data$bcOpen)
# boxplot(trimmed_loan_data$bcOpen)
trimmed_loan_data$rootbcOpen <- (trimmed_loan_data$bcOpen)^(1/6)
trimmed_loan_data$rootbcOpen[which(is.na(trimmed_loan_data$rootbcOpen))] <- mean(trimmed_loan_data$rootbcOpen, na.rm = TRUE)
summary(trimmed_loan_data$rootbcOpen)
# plot(trimmed_loan_data$rootbcOpen)
# boxplot(trimmed_loan_data$rootbcOpen)
trimmed_loan_data$bcOpen <-  NULL

#  bcOpen has a strong right skew but we can't use log transformation because of negative infinity result, so used a 6th root because it balanced the upper and lower outliers best. The new column called rootbcOpen. Replaced NA with mean values 
 
```


```{r include=FALSE, echo = FALSE}
#  bcRatio
summary(trimmed_loan_data$bcRatio)
trimmed_loan_data$bcRatio[which(is.na(trimmed_loan_data$bcRatio))] <- mean(trimmed_loan_data$bcRatio, na.rm=TRUE)
summary(trimmed_loan_data$bcRatio)
# plot(trimmed_loan_data$bcRatio)
boxplot(trimmed_loan_data$bcRatio)

# revolRatio had  384 NA that we changed to the mean. Ddoesn’t need a transformation, moderate spread and only one indication of slight outliers.
 
```

 

```{r include=FALSE, echo = FALSE}
#  totalLim
# summary(trimmed_loan_data$totalLim)
# plot(trimmed_loan_data$totalLim)
# boxplot(trimmed_loan_data$totalLim)
trimmed_loan_data$roottotalLim <- (trimmed_loan_data$totalLim)^(1/10)
# summary(trimmed_loan_data$roottotalLim)
# plot(trimmed_loan_data$roottotalLim)
# boxplot(trimmed_loan_data$roottotalLim)
trimmed_loan_data$totalLim <-  NULL

#  totalLim has a strong right skew but we can't use log transformation because of negative infinity result, so used a 10th root because it balanced the upper and lower outliers best. The new column called roottotalLim.
 
```


```{r include=FALSE, echo = FALSE}
#  totalBal
# summary(trimmed_loan_data$totalBal)
# plot(trimmed_loan_data$totalBal)
# boxplot(trimmed_loan_data$totalBal)

trimmed_loan_data$roottotalBal <- (trimmed_loan_data$totalBal)^(1/5)
# summary(trimmed_loan_data$roottotalBal)
# plot(trimmed_loan_data$roottotalBal)
# boxplot(trimmed_loan_data$roottotalBal)
trimmed_loan_data$totalBal <-  NULL

#  totalBal has a strong right skew but we can't use log transformation because of negative infinity result, so used a 5th root because it balanced the upper and lower outliers best. The new column called roottotalBal.
 
```


```{r include=FALSE, echo = FALSE}
#  totalBcLim
# summary(trimmed_loan_data$totalBcLim)
# plot(trimmed_loan_data$totalBcLim)
# boxplot(trimmed_loan_data$totalBcLim)

trimmed_loan_data$roottotalBcLim <- (trimmed_loan_data$totalBcLim)^(1/5)
# summary(trimmed_loan_data$roottotalBcLim)
# plot(trimmed_loan_data$roottotalBcLim)
# boxplot(trimmed_loan_data$roottotalBcLim)
trimmed_loan_data$totalBcLim <-  NULL

# totalBcLim has a strong right skew but we can't use log transformation because of negative infinity result, so used a 5th root because it balanced the upper and lower outliers best. The new column called roottotalBcLim.

```



```{r include=FALSE, echo = FALSE}
#  totalIlLim
# summary(trimmed_loan_data$totalIlLim)
# plot(trimmed_loan_data$totalIlLim)
# boxplot(trimmed_loan_data$totalIlLim)

trimmed_loan_data$roottotalIlLim <- (trimmed_loan_data$totalIlLim)^(1/5)
# summary(trimmed_loan_data$roottotalIlLim)
# plot(trimmed_loan_data$roottotalIlLim)
# boxplot(trimmed_loan_data$roottotalIlLim)
trimmed_loan_data$totalIlLim <-  NULL

# totalIlLim has a strong right skew but we can't use log transformation because of negative infinity result, so used a 5th root because it balanced the upper and lower outliers best. The new column called roottotalIlLim.

```


Relative to data transformation, there were 7 types of data in the dataset.

* Data that was fine the way it was, no transformation required

* Data that needed to have unused factor levels removed

* Data that lent itself to a calculated or derived field
  
    + States was used to create a new column of Region, many of the states only had a few loans but I wanted to see if geography was a factor so I grouped the states by region

* Data stored as categorical with factor levels would be better represented as a continuous dimension 

    + labels like "year 2" for a factor level has less information content than the number 2 in column year because of how 2 relates to 1 and 3

* Data that was skewed and needed a transformation

    + There were two primary transformation that were used the log base 10, and n-root transformations.

    + The n-root was used if the log transformation resulted in negative infinity values or it gave a better transformation as judged by the boxplot tails

      + The n in the n root was picked to balance the upper and lower trails of the boxplot. 

* Data that was skewed but also did not lend itself to being transformed because of a very small range (0-6)
	
* Data that had too many factor levels to be of use

    + Employment had over 21k levels and was not going to be useful to the model. 

Our data columns now look like this: 
```{r}
colnames(trimmed_loan_data)
```

```{r include=FALSE}
summary(trimmed_loan_data)
```

## Section 5 - The Logistic Model

Create "training" and "validation" dataset
Randomly choose 80% of the cases and make this into a "training"
20% of the cases are your "test" or "validation" dataset.




```{r}
set.seed(42)
# 80% of the sample size
nPercent <- .8
smp_size <- floor(nPercent * nrow(trimmed_loan_data))

train_ind <- sample(seq_len(nrow(trimmed_loan_data)), size = smp_size)

train <- trimmed_loan_data[train_ind,!names(trimmed_loan_data) %in% c('totalPaid','state') ]
test <- trimmed_loan_data[-train_ind, ]

length(test$response[test$response == 'Good']) / length(test$response)

```


```{r include=FALSE}
# Forward

# d_set <- train # to train the model
# full_fit <- glm(response ~ . , data = d_set, family="binomial")
# null_fit <- glm(response~1,data=d_set, family = 'binomial')
# old_AIC <-  0;
# old_accuracy <- 0;
# last_AIC <-  0;
# last_accuracy <- 0;
# max_accuracy <-  0;
# max_accuracy_i <-  0;
# max_accuracy_AIC <- 0;
# max_formula <-  '';
# i <- 0
# n <- 500
# print('forward')
# repeat {
#   d_set <- train # to train the model
#   forward_out <- step(null_fit,scope=list(lower=null_fit,upper=full_fit),direction="forward",steps = 1, trace = 0)
#   null_fit <- glm(forward_out$formula,data=d_set, family = 'binomial')
#   # print(c('AIC: ',round(extractAIC(forward_out)[2],0)))
#   d_set <- test # to test the model
#   d_set$fw.prob <- predict(forward_out, d_set, type="response")
#   accuracy_forward <- (length(d_set$fw.prob[c(d_set$fw.prob >=.5 & d_set$response == 'Good')]) +            length(d_set$fw.prob[c(d_set$pfw.redict <.5 & d_set$response == 'Bad')])) / length(d_set$fw.prob)
#   # print(c('Accuracy Rate:',round(accuracy_forward,3)))
#   
#   if(accuracy_forward > max_accuracy){
#     max_accuracy <- accuracy_forward
#     max_formula <- forward_out$call
#     max_accuracy_AIC <- extractAIC(forward_out)
#     max_accuracy_i <- i
#   }
#   
#   old_AIC <-  extractAIC(forward_out)[2];
#   old_accuracy <-  accuracy_forward;
#   old_call <- forward_out$call
#   
#   if(last_AIC == extractAIC(forward_out)[2] & last_accuracy == accuracy_forward & i%%10 == 0){
#     break;
#     }
#   if(i%%10 == 0){
# 
#     last_AIC <-  extractAIC(forward_out)[2];
#     last_accuracy <-  accuracy_forward;
#     
#     print('------------------------------------------')
#     print(Sys.time());
#     print(c('i:',i));  
#     print(c('Final Accuracy Rate:',round(accuracy_forward,3)))
#     print(c('Final AIC: ',round(extractAIC(forward_out)[2],0)))
#     print(c('Final Formula',forward_out$call))
#   } 
#   
#   i <- i + 1
# }
#  
# paste('max accuracy i:',max_accuracy_i)
# paste('max accuracy:',round(max_accuracy,3))
# paste('max accuracy AIC:',round(max_accuracy_AIC[2],0))
# print(c('max formula:',max_formula))
# print('vs')
# paste('Max i:',i)
# print(c('Final Accuracy Rate:',round(accuracy_forward,3)))
# print(c('Final AIC: ',round(extractAIC(forward_out)[2],0)))
# print(c('Final Formula',forward_out$call))


# Forward
# High accuracy:
# "max accuracy i: 0"
# "max accuracy: 0.767"
# "max accuracy AIC: 27114"
# glm(formula = response ~ rate, family = "binomial", data = d_set)

# Low AIC:
# "Final Accuracy Rate:" "0.759"               
# "Final AIC: " "26211"      
# glm(formula = response ~ rate + term + avgBal + debtIncRat + 
#     rootaccOpen24 + roottotalLim + logPayment + logTotalAcc + 
#     delinq2yr + roottotalBal + home + amount + region + rootbcOpen + 
#     openAcc + rootTotalRevBal + reason + revolRatio + bcRatio + 
#     inq6mth + verified, family = "binomial", data = d_set)



```

```{r include=FALSE}
# Backward

# d_set <- train # to train the model
# full_fit <- glm(response ~ . , data = d_set, family="binomial")
# null_fit <- glm(response~1,data=d_set, family = 'binomial')
# old_AIC <-  0;
# old_accuracy <- 0;
# last_AIC <-  0;
# last_accuracy <- 0;
# max_accuracy <-  0;
# max_accuracy_i <-  0;
# max_accuracy_AIC <- 0;
# max_formula <-  '';
# i <- 0
# n <- 500
# print('backward')
# repeat {
#   d_set <- train # to train the model
#   backward_out <- step(full_fit,direction="backward",steps = 1, trace = 0)
#   # print(c('AIC: ',round(extractAIC(backward_out)[2],0)))
#   full_fit <- glm(backward_out$formula,data=d_set, family = 'binomial')
#   # print(backward_out$formula)
#   d_set <- test # to test the model
#   d_set$bw.prob <- predict(backward_out, d_set, type="response")
#   accuracy_backward <- (length(d_set$bw.prob[c(d_set$bw.prob >=.5 & d_set$response == 'Good')]) +            length(d_set$bw.prob[c(d_set$bw.prob <.5 & d_set$response == 'Bad')])) / length(d_set$bw.prob)
#   # print(c('Accuracy Rate:',round(accuracy_backward,3)))
#
#   if(accuracy_backward > max_accuracy){
#     max_accuracy <- accuracy_backward
#     max_formula <- backward_out$call
#     max_accuracy_AIC <- extractAIC(backward_out)
#     max_accuracy_i <- i
#   }
#
#     if(i == n){
#       break;
#     }
#
#
#   if(last_AIC == extractAIC(backward_out)[2] & last_accuracy == accuracy_backward & i%%10 == 0){
#       break;
#     }
#
#   if(i%%10 == 0){
#
#     last_AIC <-  extractAIC(backward_out)[2];
#     last_accuracy <-  accuracy_backward;
#
#     print('------------------------------------------')
#     print(Sys.time());
#     print(c('i:',i));
#     print(c('Final Accuracy Rate:',round(accuracy_backward,3)))
#     print(c('Final AIC: ',round(extractAIC(backward_out)[2],0)))
#     print(c('Final Formula',backward_out$call))
#   }
#
#   old_AIC <-  extractAIC(backward_out)[2];
#   old_accuracy <-  accuracy_backward;
#   old_call <- backward_out$call
#
#
#
#   i <- i + 1
#
# }
#
# print('#########################################')
#
# paste('max accuracy i:',max_accuracy_i)
# paste('max accuracy:',round(max_accuracy,3))
# paste('max accuracy AIC:',round(max_accuracy_AIC[2],0))
# print(c('max formula:',max_formula))
# print('vs')
# paste('Max i:',i)
# print(c('Final Accuracy Rate:',round(accuracy_backward,3)))
# print(c('Final AIC: ',round(extractAIC(backward_out)[2],0)))
# print(c('Final Formula',backward_out$call))


# Backward
# High accuracy:
# "max accuracy i: 6"
# "max accuracy: 0.789"
# "max accuracy AIC: 26210"
# glm(formula = response ~ amount + term + rate + home + verified +
#     reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio +
#     bcRatio + logPayment + logIncome + region + logTotalAcc +
#     rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim +
#     roottotalBal + roottotalBcLim, family = "binomial", data = d_set)

# Low AIC:
# "Final Accuracy Rate:" "0.788"
# "Final AIC: " "26209"
# glm(formula = response ~ amount + term + rate + home + verified +
#     reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio +
#     bcRatio + logPayment + region + logTotalAcc + rootTotalRevBal +
#     rootaccOpen24 + rootbcOpen + roottotalLim + roottotalBal,
#     family = "binomial", data = d_set)


```

```{r}
# Both

d_set <- train # to train the model
full_fit <- glm(response ~ . , data = d_set, family="binomial")
null_fit <- glm(response~1,data=d_set, family = 'binomial')
old_AIC <-  0
old_accuracy <- 0
last_AIC <-  0
last_accuracy <- 0
max_accuracy <-  0
max_accuracy_i <-  matrix(c(0,0),nrow=2)
max_accuracy_AIC <- 0
max_acc_formula <-  ''
max_profit <-  0
max_profit_i <-  matrix(c(0,0),nrow=2)
max_profit_AIC <- 0
max_prof_formula <-  ''
i <- 1
n <- 100
print('both')
repeat {
  d_set <- train # to train the model
  both_out <- step(full_fit,direction="both",steps = 1, trace = 0)
  # print(c('AIC: ',round(extractAIC(both_out)[2],0)))
  full_fit <- glm(both_out$formula,data=d_set, family = 'binomial')
  # print(both_out$formula)
  d_set <- test # to test the model
  d_set$b.prob <- predict(both_out, d_set, type="response")
  # predprob  <- predict(temp, d_set, type="response")

# ##################################################

  for(j in seq(1,99)){
  
    threshhold <- j/100  # Set Y=1 when predicted probability exceeds this
    predLoan <- cut(d_set$b.prob, breaks=c(-Inf, threshhold, Inf),labels=c("Bad", "Good"))  # Y=1 is "Bad"
    predict <- predLoan

# Accuracy   
    cTab <- table(d_set$response, predLoan) 
    # addmargins(cTab)
    
    accuracy_b  <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
    # print(paste('Proportion correctly predicted = ', accuracy_b)) 
    
# Profit    
    profit_b <- 0 

    # Paid - $500 to put into default and try to collect - 1.1amount
    profit_b <- sum(d_set$totalPaid[predict == 'Good' &  d_set$response == 'Bad'] - 500 - d_set$amount[predict == 'Good' & d_set$response == 'Bad'])
    
    # # Made profitable loan
    profit_b <- profit_b + sum(d_set$totalPaid[predict == 'Good' & d_set$response == 'Good'] - d_set$amount[predict == 'Good' & d_set$response == 'Good'])
  # print(c('profit',i,j,profit_b))

  
# ##################################################
  
    if(accuracy_b > max_accuracy){
      max_accuracy <- accuracy_b
      max_acc_formula <- both_out$call
      max_accuracy_AIC <- extractAIC(both_out)
      max_accuracy_i <- matrix(c(i,j),nrow=2)
    } # End if max accuracy
    
    if(profit_b > max_profit){
      print(c('new max profit', 'i:',i, 'j',j, '$',profit_b))
      max_profit <- profit_b
      max_prof_formula <- both_out$call
      max_profit_AIC<- extractAIC(both_out)
      max_profit_i <- matrix(c(i,j),nrow=2)
    } # End if max profit
  } # End j 1 to 100
  
  if(i == n){ 
    print('------------------------------------------')
    print(Sys.time())
    print(c('i:',i))
    print(c('Final Accuracy Rate:',round(accuracy_b,3)))
    print(c('Final AIC: ',round(extractAIC(both_out)[2],0)))
    print(c('Final Formula',both_out$call))
    break
    } # End if(i == n)

  old_AIC <-  extractAIC(both_out)[2];
  old_accuracy <-  accuracy_b;
  old_call <- both_out$call

  if(last_AIC == extractAIC(both_out)[2] & last_accuracy == accuracy_b & i%%10 == 0){break}

  if(i%%10 == 0){

    last_AIC <-  extractAIC(both_out)[2];
    last_accuracy <-  accuracy_b;

    print('------------------------------------------')
    print(Sys.time())
    print(c('i:',i))
    print(c('Final Accuracy Rate:',round(accuracy_b,3)))
    print(c('Final AIC: ',round(extractAIC(both_out)[2],0)))
    print(c('Final Formula',both_out$call))
  } # End if (i%%10 == 0)

  i <- i + 1
  print(c('i:',i))
} # End repeat

# Both
# High accuracy:
# "max accuracy i: 6"
# "max accuracy: 0.789"
# "max accuracy AIC: 26210"
# glm(formula = response ~ amount + term + rate + home + verified + 
#     reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + 
#     bcRatio + logPayment + logIncome + region + logTotalAcc + 
#     rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim + 
#     roottotalBal + roottotalBcLim, family = "binomial", data = d_set)

# Low AIC:
# "Final Accuracy Rate:" "0.788"               
# "Final AIC: " "26209"      
# "Final Formula"
# glm(formula = response ~ amount + term + rate + home + verified + 
#     reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + 
#     bcRatio + logPayment + region + logTotalAcc + rootTotalRevBal + 
#     rootaccOpen24 + rootbcOpen + roottotalLim + roottotalBal, 
#     family = "binomial", data = d_set)
```

```{r}

paste('max profit i:',max_profit_i[1])
paste('max profit j:',max_profit_i[2])
paste('max profit:',round(max_profit,3))
paste('max profit AIC:',round(max_profit_AIC[2],0))
print(c('max profit formula:',max_prof_formula))
print('vs')
paste('max accuracy i:',max_accuracy_i[1])
paste('max accuracy j:',max_accuracy_i[2])
paste('max accuracy:',round(max_accuracy,3))
paste('max accuracy AIC:',round(max_accuracy_AIC[2],0))
print(c('max formula:',max_acc_formula))
print('vs')
paste('Max i:',i)
print(c('Final Accuracy Rate:',round(accuracy_b,3)))
print(c('Final Profit:',round(profit_b,3)))
print(c('Final AIC: ',round(extractAIC(both_out)[2],0)))
print(c('Final Formula',both_out$call))
```

```{r include=FALSE}
# second Order

# d_set <- train # to train the model
# # step(forward_out,scope = . ~ . ^2 , direction="forward")
# # full_fit <- glm(both_out$formula, data = d_set, family="binomial")
# full_fit <- glm(formula = response ~ amount + term + rate + home + verified + 
#     reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + 
#     bcRatio + logPayment + logIncome + region + logTotalAcc + 
#     rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim + 
#     roottotalBal + roottotalBcLim, family = "binomial", data = d_set)
# null_fit <- glm(response~1,data=d_set, family = 'binomial')
# old_AIC <-  0;
# old_accuracy <- 0;
# last_AIC <-  0;
# last_accuracy <- 0;
# max_accuracy <-  0;
# max_accuracy_i <-  0;
# max_accuracy_AIC <- 0;
# max_formula <-  '';
# i <- 0
# n <- 500
# print('second order')
# repeat {
#   d_set <- train # to train the model
#   second_Order_out <- step(full_fit,scope = . ~ . ^2 ,direction="both",steps = 1, trace = 0)
#   full_fit <- glm(second_Order_out$formula,data=d_set, family = 'binomial')
#   # print(c('AIC: ',round(extractAIC(second_Order_out)[2],0)))
#   # print(second_Order_out$formula)
#   d_set <- test # to test the model
#   d_set$sec.prob <- predict(second_Order_out, d_set, type="response")
#   accuracy_sec <- (length(d_set$sec.prob[c(d_set$sec.prob >=.5 & d_set$response == 'Good')]) +            length(d_set$sec.prob[c(d_set$sec.prob <.5 & d_set$response == 'Bad')])) / length(d_set$sec.prob)
#   # print(c('Accuracy Rate:',round(accuracy_sec,3)))
#   
#   if(accuracy_sec > max_accuracy){
#     max_accuracy <- accuracy_sec
#     max_formula <- second_Order_out$call
#     max_accuracy_AIC <- extractAIC(second_Order_out)
#     max_accuracy_i <- i
#   }
#   
#   if(i == n){
#     break;
#   }
#   
#   old_AIC <-  extractAIC(second_Order_out)[2];
#   old_accuracy <-  accuracy_sec;
#   old_call <- second_Order_out$call
#   
#   if(last_AIC == extractAIC(second_Order_out)[2] & last_accuracy == accuracy_sec & i%%10 == 0 ){
#       break;
#     }
#   
#   if(i%%10 == 0){
# 
#     last_AIC <-  extractAIC(second_Order_out)[2];
#     last_accuracy <-  accuracy_sec;
#     
#     print('------------------------------------------')
#     print(Sys.time());
#     print(c('i:',i));  
#     print(c('Final Accuracy Rate:',round(accuracy_sec,3)));
#     print(c('Final AIC: ',round(extractAIC(second_Order_out)[2],0)));
#     print(c('Final Formula',second_Order_out$call));
#   }  
#   
#   i <- i + 1
# }
# 
# print('#########################################')
#  
# paste('max accuracy i:',max_accuracy_i)
# paste('max accuracy:',round(max_accuracy,3))
# paste('max accuracy AIC:',round(max_accuracy_AIC[2],0))
# print(c('max formula:',max_formula))
# print('vs')
# paste( 'i:',i)
# print(c('Final Accuracy Rate:',round(accuracy_sec,3)))
# print(c('Final AIC: ',round(extractAIC(second_Order_out)[2],0)))
# print(c('Final Formula',second_Order_out$call))



# Second Order
# High accuracy:
# "max accuracy i: 11"
# "max accuracy: 0.79"
# "max accuracy AIC: 26084"
# "max formula:"
# glm(formula = response ~ amount + term + rate + home + verified + 
#     reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + 
#     bcRatio + logPayment + logIncome + region + logTotalAcc + 
#     rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim + 
#     roottotalBal + roottotalBcLim + term:roottotalBal + logPayment:roottotalBcLim + 
#     term:rate + rate:roottotalBal + verified:openAcc + amount:delinq2yr + 
#     reason:rootbcOpen + delinq2yr:logTotalAcc + region:rootbcOpen + 
#     rate:delinq2yr + rate:rootaccOpen24 + rate:revolRatio, family = "binomial", 
#     data = d_set)

# Low AIC:
# "i: 70"
# "Final Accuracy Rate:" "0.789"               
# "Final AIC: " "25999"      
# "Final Formula"
# glm(formula = response ~ amount + term + rate + home + verified + 
#     reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + 
#     bcRatio + logPayment + logIncome + region + logTotalAcc + 
#     rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim + 
#     roottotalBal + roottotalBcLim + term:roottotalBal + logPayment:roottotalBcLim + 
#     term:rate + rate:roottotalBal + verified:openAcc + amount:delinq2yr + 
#     reason:rootbcOpen + delinq2yr:logTotalAcc + rate:delinq2yr + 
#     rate:revolRatio + rate:rootTotalRevBal + rootbcOpen:roottotalBcLim + 
#     openAcc:rootbcOpen + rate:openAcc + verified:logPayment + 
#     region:roottotalBal + openAcc:region + delinq2yr:region + 
#     term:home + logPayment:rootTotalRevBal + rootbcOpen:roottotalLim + 
#     term:debtIncRat + bcRatio:roottotalLim + logIncome:rootaccOpen24 + 
#     logIncome:logTotalAcc + amount:logIncome + delinq2yr:logIncome + 
#     verified:debtIncRat + rootaccOpen24:roottotalLim + debtIncRat:rootaccOpen24 + 
#     term:region + verified:rootaccOpen24 + debtIncRat:bcRatio + 
#     debtIncRat:rootbcOpen + debtIncRat:roottotalBal + revolRatio:rootaccOpen24 + 
#     openAcc:roottotalBal + amount:logTotalAcc + rate:logTotalAcc + 
#     region:roottotalLim + logPayment:rootbcOpen + debtIncRat:logIncome + 
#     home:debtIncRat + rate:rootbcOpen + term:rootbcOpen + bcRatio:roottotalBcLim + 
#     openAcc:region:roottotalBal, family = "binomial", data = d_set)


```


```{r}
# Test the diffrent versions:
d_set <- train # to train the model

fw1_out <- glm(formula = response ~ rate, family = "binomial", data = d_set)

fw2_out <- glm(formula = response ~ rate + term + avgBal + debtIncRat +rootaccOpen24 + roottotalLim + logPayment + logTotalAcc + delinq2yr + roottotalBal + home + amount + region + rootbcOpen + openAcc + rootTotalRevBal + reason + revolRatio + bcRatio + inq6mth + verified, family = "binomial", data = d_set)


bw1_out <- glm(formula = response ~ amount + term + rate + home + verified + reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + bcRatio + logPayment + logIncome + region + logTotalAcc +  rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim + roottotalBal + roottotalBcLim, family = "binomial", data = d_set)

bw2_out <- glm(formula = response ~ amount + term + rate + home + verified + reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + bcRatio + logPayment + region + logTotalAcc + rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim + roottotalBal, family = "binomial", data = d_set)  

# dup of bw1_out
# b1_out <- glm(formula = response ~ amount + term + rate + home + verified + reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + bcRatio + logPayment + logIncome + region + logTotalAcc + rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim + roottotalBal + roottotalBcLim, family = "binomial", data = d_set)
# dup of bw2_out
# b2_out <-  glm(formula = response ~ amount + term + rate + home + verified + reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + bcRatio + logPayment + region + logTotalAcc + rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim + roottotalBal, family = "binomial", data = d_set)
  

sec1_out <- glm(formula = response ~ amount + term + rate + home + verified +  reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + bcRatio + logPayment + logIncome + region + logTotalAcc + rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim +  roottotalBal + roottotalBcLim + term:roottotalBal + logPayment:roottotalBcLim + term:rate + rate:roottotalBal + verified:openAcc + amount:delinq2yr +  reason:rootbcOpen + delinq2yr:logTotalAcc + region:rootbcOpen + rate:delinq2yr + rate:rootaccOpen24 + rate:revolRatio, family = "binomial", data = d_set)

sec2_out <- glm(formula = response ~ amount + term + rate + home + verified + reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio +  bcRatio + logPayment + logIncome + region + logTotalAcc + rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim +  roottotalBal + roottotalBcLim + term:roottotalBal + logPayment:roottotalBcLim + term:rate + rate:roottotalBal + verified:openAcc + amount:delinq2yr + reason:rootbcOpen + delinq2yr:logTotalAcc + rate:delinq2yr +  rate:revolRatio + rate:rootTotalRevBal + rootbcOpen:roottotalBcLim +  openAcc:rootbcOpen + rate:openAcc + verified:logPayment + region:roottotalBal + openAcc:region + delinq2yr:region + term:home + logPayment:rootTotalRevBal + rootbcOpen:roottotalLim + term:debtIncRat + bcRatio:roottotalLim + logIncome:rootaccOpen24 + logIncome:logTotalAcc + amount:logIncome + delinq2yr:logIncome + verified:debtIncRat + rootaccOpen24:roottotalLim + debtIncRat:rootaccOpen24 + term:region + verified:rootaccOpen24 + debtIncRat:bcRatio + debtIncRat:rootbcOpen + debtIncRat:roottotalBal + revolRatio:rootaccOpen24 + openAcc:roottotalBal + amount:logTotalAcc + rate:logTotalAcc + region:roottotalLim + logPayment:rootbcOpen + debtIncRat:logIncome +  home:debtIncRat + rate:rootbcOpen + term:rootbcOpen + bcRatio:roottotalBcLim + openAcc:region:roottotalBal, family = "binomial", data = d_set)   

```
```{r}
# install.packages('broom')
require('broom')
g_fw1 <- glance(fw1_out)
g_fw2 <- glance(fw2_out)
g_bw1 <- glance(bw1_out)
g_bw2 <- glance(bw2_out)
g_sec1 <- glance(sec1_out)
g_sec2 <- glance(sec2_out)

```

Find "Best" Model

```{r warning=FALSE} 
d_set <- test # to test the model
bad <- list()
good <- list()
percentBadRej <- list()
percentGoodRej <- list()
profit_threshold <- list()
profit_table <- matrix(, nrow = 0, ncol = 100)
profit_max <- list()
accuracy_threshold <- list()
accuracy_table <- matrix(, nrow = 0, ncol = 100)
accuracy_max <- list()
percentBadRej <- matrix(, nrow = 0, ncol = 100)
percentGoodRej <- matrix(, nrow = 0, ncol = 100)

mods_list <- c(fw1_out$formula,fw2_out$formula, bw1_out$formula,bw2_out$formula,sec1_out$formula,sec2_out$formula)


for (j in seq(1:length(mods_list))){

  temp <- glm(mods_list[j][[1]], family = "binomial", data = d_set) 
  predprob  <- predict(temp, d_set, type="response")

  profit_table_temp <- NULL  
  accuracy_table_temp <- NULL
  percentBadRej_temp <- NULL
  percentGoodRej_temp <- NULL
  for(i in seq(1,100)){
  
    threshhold <- i/100  # Set Y=1 when predicted probability exceeds this
    predLoan <- cut(predprob, breaks=c(-Inf, threshhold, Inf),labels=c("Bad", "Good"))  # Y=1 is "Bad"
    predict <- predLoan

# Accuracy    
    cTab <- table(d_set$response, predLoan) 
    # addmargins(cTab)
    
    p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
    # print(paste('Proportion correctly predicted = ', p)) 
    accuracy_table_temp[i] <- p
    bad[i] <- length(predLoan[predLoan == 'Bad'])
    good[i] <- length(predLoan[predLoan == 'Good'])
  
    percentBadRej_temp[i] <- length(d_set$response[predict == 'Bad' & d_set$response == 'Bad'])/ 
      length( d_set$response[d_set$response == 'Bad'])
    
    percentGoodRej_temp[i] <- length(d_set$response[predict == 'Bad' & d_set$response == 'Good'])/ 
      length( d_set$response[d_set$response == 'Good'])
    
    
# Profit    
    d_set$profit <- 0 

    # Paid - $500 to put into default and try to collect - 1.1amount
    d_set$profit[predict == 'Good' & d_set$response == 'Bad'] <- d_set$totalPaid[predict == 'Good' &  d_set$response == 'Bad'] - 500 - d_set$amount[predict == 'Good' & d_set$response == 'Bad']
    
    # # Made profitable loan
    d_set$profit[predict == 'Good' & d_set$response == 'Good'] <- d_set$totalPaid[predict == 'Good' & d_set$response == 'Good'] - d_set$amount[predict == 'Good' & d_set$response == 'Good']


  p <- sum(d_set$profit)# compute the pro vs lose 
  # print(paste0('i:',i,', p: ',p))
  profit_table_temp[i] <- p
  
  }
#   print('----------------------')  
  percentBadRej <- rbind(percentBadRej, percentBadRej_temp)
  percentGoodRej <- rbind(percentGoodRej, percentGoodRej_temp)
  accuracy_table <- rbind(accuracy_table, accuracy_table_temp)
  profit_table <- rbind(profit_table, profit_table_temp)
#   print(j)
  profit_threshold[j] <- which.max(profit_table[j,])
#   print(profit_threshold[j])
  profit_max[j] <- profit_table[j,profit_threshold[j][[1]]]
#   print(profit_max[j])
  accuracy_threshold[j] <- which.max(accuracy_table[j,])
#   print(accuracy_threshold[j])
  accuracy_max[j] <- accuracy_table[j,accuracy_threshold[j][[1]]]
#   print(accuracy_max[j])
}



```
```{r}
d_set <- test # to test the model

act_profit <- (sum(d_set$totalPaid) - sum(d_set$amount) - 500 * length(d_set$amount[d_set$response=='Bad'])) 
perfect_profit <- (sum(d_set$totalPaid[d_set$response=='Good']) - sum(d_set$amount[d_set$response=='Good']))

r <- c('fw1_out', 'fw2_out', 'bw1_out', 'bw2_out', 'sec1_out', 'sec2_out')
c <- c( 'AIC',	'BIC',	'Max Acc',	'Acc Cutoff',	'Max Profit',	'Profit Cut','% Improved', '% Perfect')
glance_matrix <- matrix(c(
g_fw1[4],	 g_fw1[5],	round(accuracy_max[[1]],3),	accuracy_threshold[1],	profit_max[1],	profit_threshold[1], round(profit_max[[1]]/act_profit,3)*100, round(profit_max[[1]]/perfect_profit,3)*100,
 g_fw2[4],	 g_fw2[5],	round(accuracy_max[[2]],3),	accuracy_threshold[2],	profit_max[2],	profit_threshold[2], round(profit_max[[2]]/act_profit,3)*100, round(profit_max[[2]]/perfect_profit,3)*100,
 g_bw1[4],	 g_bw1[5],	round(accuracy_max[[3]],3),	accuracy_threshold[3],	profit_max[3],	profit_threshold[3], round(profit_max[[3]]/act_profit,3)*100, round(profit_max[[3]]/perfect_profit,3)*100,
 g_bw2[4],	 g_bw2[5],	round(accuracy_max[[4]],3),	accuracy_threshold[4],	profit_max[4],	profit_threshold[4], round(profit_max[[4]]/act_profit,3)*100, round(profit_max[[4]]/perfect_profit,3)*100,
 g_sec1[4],	 g_sec1[5],	round(accuracy_max[[5]],3),	accuracy_threshold[5],	profit_max[5],	profit_threshold[5], round(profit_max[[5]]/act_profit,3)*100, round(profit_max[[5]]/perfect_profit,3)*100,
 g_sec2[4],	 g_sec2[5],	round(accuracy_max[[6]],3),	accuracy_threshold[6],	profit_max[6],	profit_threshold[6], round(profit_max[[6]]/act_profit,3)*100, round(profit_max[[6]]/perfect_profit,3)*100)
, nrow = 6, byrow = TRUE,dimnames = list(r,c) ) 

glance_matrix 


```


The Profitability vs Algorithm Approval Threshold graph shows how profit is impacted by making bad loans and rejecting good loans. 

profit_table[j,]

```{r echo=FALSE, fig.width=8, fig.height=11}
par(mfrow=c(3,3), mar=c(5,4,4,2))
plot(1,axes = FALSE, ann = FALSE, col = "white" )
plot(1,axes = FALSE, ann = FALSE, col = "white", main='Profitability vs Algorithm Approval Threshold' )
legend('center', inset = c(-10,-10),title='legend',legend=c('Current Process Profit','Profit as % of Max','Accuracy Cutoff','Profit Cutoff','% Bad Loans Rejected','% Good Loans Rejected'), col=c('black','blue','red','green','darkmagenta','darkgreen'), lty=c(4,1,1,1,1,1), cex=1.25)

plot(1,axes = FALSE, ann = FALSE, col = "white" )

for(j in seq(1,6)){
  # plot((profit_table[j,])/(max(profit_table))*100, type='l', col='blue', ylim=c(-10 ,100), xlab='Algorithm Approval Threshold', ylab='Percentage', main='Profitability vs Algorithm Approval Threshold' )
    plot((profit_table[j,])/(max(profit_table))*100, type='l', col='blue', ylim=c(-10 ,100), xlab='Approval Threshold', ylab='Percentage', main=rownames(glance_matrix)[j] )
  
  lines(x=seq(1,100),y= percentBadRej[j,]* 100,  col='darkmagenta')
  lines(x=seq(1,100),y= percentGoodRej[j,]* 100,  col='darkgreen')
  # abline(h= act_profit/ max(profit_table[j,])*100, col='black', lty=4)
  abline(h= act_profit/ max(profit_table)*100, col='black', lty=4)
  abline(v=which.max(accuracy_table[j,]), col='red')
  abline(v=which.max(profit_table[j,]), col='green')
  abline(h=max(profit_table[j,])/ max(profit_table)*100, col='blue')
  
}

```








## Section 7 - Optimizing the Threshold for Profit

```{r }
d_set <- test # to test the model
d_set$prob <- predict(both_out, d_set, type="response")
predprob <- d_set$prob # get predicted probabilities
profit_table <- numeric()

for(i in seq(1,100)){
  threshhold <- i/100  # Set Y=1 when predicted probability exceeds this
  # print(threshhold)
  predLoan <- cut(predprob, breaks=c(-Inf, threshhold, Inf), labels=c("Bad", "Good"))  # Y=1 is "Bad"
  d_set$predict <- predLoan
  d_set$profit <- 0 
 
  # Paid - $1000 to put into default and try to collect - 1.1amount
  d_set$profit[d_set$predict == 'Good' & d_set$response == 'Bad'] <- d_set$totalPaid[d_set$predict == 'Good' &  d_set$response == 'Bad'] - 500 - d_set$amount[d_set$predict == 'Good' & d_set$response == 'Bad']
  
  # # Made profitable loan
  d_set$profit[d_set$predict == 'Good' & d_set$response == 'Good'] <- d_set$totalPaid[d_set$predict == 'Good' & d_set$response == 'Good'] - d_set$amount[d_set$predict == 'Good' & d_set$response == 'Good']


  p <- sum(d_set$profit)# compute the pro vs lose 
  # print(paste0('i:',i,', p: ',p))
  profit_table[i] <- p
  bad[i] <- length(predLoan[predLoan == 'Bad'])
  good[i] <- length(predLoan[predLoan == 'Good'])
}

no_penalty_threshold <- which.max(profit_table)

pre_model <- (sum(d_set$totalPaid) - sum(d_set$amount) - 500 * length(d_set$amount[d_set$response=='Bad'])) 
pre_model

no_penalty_max <- max(profit_table)
no_penalty_max

perfect_profit <-  (sum(d_set$totalPaid[d_set$response=='Good']) - sum(d_set$amount[d_set$response=='Good']))
perfect_profit

paste('model improvement:', no_penalty_max/pre_model )
paste('ideal model improvement', perfect_profit /no_penalty_max)

true_bad <- d_set$response[which(d_set$response == 'Bad' & predprob < no_penalty_threshold/100)]
true_good <- d_set$response[which(d_set$response == 'Good' & predprob >= no_penalty_threshold/100)] 

which.max(profit_table)

percent_accurate <- (length(true_bad) + length(true_good))/length(d_set$response)
percent_accurate
percent_bad <- length(true_bad)/length(d_set$response[d_set$response=='Bad'])
percent_bad
percent_good <- length(true_good)/length(d_set$response[d_set$response=='Good']) 
percent_good

```


Build with Train, and validate with Test, see which is better as a % accuracy
I built and compared 5 Generalized Linear Models: 
########## FIX THIS ############
# ```{r include=FALSE}
```{r }
d_set <- train # to train the model
d_set <- test # to test the model
# d_set <- trimmed_loan_data[,!names(trimmed_loan_data) %in% c('totalPaid','state') ]


full_fit <- glm(response ~ . , data = d_set, family="binomial")
null_fit <- glm(response~1,data=d_set, family = 'binomial')

Sys.time()
print('forward')
# forward_out <- step(null_fit,scope=list(lower=null_fit,upper=full_fit),direction="forward", trace = 0)
d_set <- train # to train the model
forward_out <- glm(response ~ rate + term + avgBal + debtIncRat + rootaccOpen24 + 
roottotalLim + logPayment + logTotalAcc + delinq2yr + roottotalBal + 
home + amount + region + rootbcOpen + openAcc + rootTotalRevBal + 
reason + revolRatio + bcRatio + inq6mth + verified, family = "binomial", data = d_set)
paste('AIC: ',round(extractAIC(forward_out)[2],0))
d_set <- test # to test the model
d_set$fw.prob <- predict(forward_out, d_set, type="response")
accuracy_forward <- (length(d_set$fw.prob[c(d_set$fw.prob >=.5 & d_set$response == 'Good')]) +            length(d_set$fw.prob[c(d_set$pfw.redict <.5 & d_set$response == 'Bad')])) / length(d_set$fw.prob)
paste('Accuracy Rate:',round(accuracy_forward,3))
Sys.time()
print('##############################')
print('backward')
# backward_out <- step(full_fit,direction="backward", trace = 0)
d_set <- train # to train the model
backward_out <- glm(response ~ amount + term + rate + home + verified + reason + 
debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + 
bcRatio + logPayment + region + logTotalAcc + rootTotalRevBal + 
rootaccOpen24 + rootbcOpen + roottotalLim + roottotalBal, family = "binomial", data = d_set )
paste('AIC: ',round(extractAIC(backward_out)[2],0))
d_set <- test # to test the model
d_set$bw.prob <- predict(backward_out, d_set, type="response")
accuracy_backward <- (length(d_set$bw.prob[c(d_set$bw.prob >=.5 & d_set$response == 'Good')]) +            length(d_set$bw.prob[c(d_set$bw.prob <.5 & d_set$response == 'Bad')])) / length(d_set$bw.prob)
paste('Accuracy Rate:',round(accuracy_backward,3))
Sys.time()
print('##############################')
print('both')
# both_out <- step(null_fit,scope=list(lower=null_fit,upper=full_fit),direction="both", trace = 0)
d_set <- train # to train the model
both_out <- glm(response ~ rate + term + debtIncRat + rootaccOpen24 + roottotalLim + 
logPayment + logTotalAcc + delinq2yr + roottotalBal + home + 
amount + region + rootbcOpen + openAcc + rootTotalRevBal + 
reason + revolRatio + bcRatio + inq6mth + verified, family = "binomial", data = d_set  )
paste('AIC: ',round(extractAIC(both_out)[2],0))
d_set <- test # to test the model
d_set$b.prob <- predict(both_out, d_set, type="response")
accuracy_b <- (length(d_set$b.prob[c(d_set$b.prob >=.5 & d_set$response == 'Good')]) +            length(d_set$b.prob[c(d_set$b.prob <.5 & d_set$response == 'Bad')])) / length(d_set$b.prob)
paste('Accuracy Rate:',round(accuracy_b,3))
Sys.time()
print('##############################')
print('2nd Order')
d_set <- train # to train the model
second_Order_out <- glm(formula = response ~ amount + term + rate + home + verified + 
reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + 
bcRatio + logPayment + region + logTotalAcc + rootTotalRevBal + 
rootaccOpen24 + rootbcOpen + roottotalLim + roottotalBal + 
term:roottotalBal + term:rate + rate:roottotalBal + verified:openAcc + 
amount:delinq2yr + reason:rootbcOpen + region:rootbcOpen + 
delinq2yr:openAcc + delinq2yr:region + region:roottotalBal + 
openAcc:region + verified:logPayment + rate:home + rate:delinq2yr + 
rate:rootaccOpen24 + rate:revolRatio + rate:rootTotalRevBal + 
debtIncRat:bcRatio + debtIncRat:rootbcOpen + debtIncRat:roottotalBal + 
home:openAcc + logPayment:rootTotalRevBal + openAcc:rootbcOpen + 
rootbcOpen:roottotalLim + rate:openAcc + logPayment:rootbcOpen + 
term:debtIncRat + verified:debtIncRat + term:region + debtIncRat:revolRatio + 
bcRatio:roottotalBal + amount:revolRatio + term:revolRatio, 
family = "binomial", data = d_set)
paste('AIC: ',round(extractAIC(second_Order_out)[2],0))
d_set <- test # to test the model
d_set$two.prob <- predict(second_Order_out, d_set, type="response")
accuracy_two <- (length(d_set$two.prob[c(d_set$two.prob >=.5 & d_set$response == 'Good')]) +            length(d_set$two.prob[c(d_set$two.prob <.5 & d_set$response == 'Bad')])) / length(d_set$two.prob)
paste('Accuracy Rate:',round(accuracy_two,3))
Sys.time()
print('##############################')
print('2nd Order Old')
d_set <- train # to train the model
second_Order_out_old <- glm(formula=response~term+roottotalLim+rootaccOpen24+debtIncRat+rootbcOpen+logPayment+reason+logTotalAcc+inq6mth+delinq2yr+logIncome+revolRatio+home+openAcc+verified+roottotalBcLim+region+roottotalIlLim+roottotalBal+amount+bcRatio+pubRec+logPayment:amount+logPayment:roottotalBcLim+openAcc:verified+term:logPayment+term:roottotalBal+openAcc:region+logPayment:delinq2yr+revolRatio:pubRec+verified:amount+logTotalAcc:logIncome+delinq2yr:openAcc+term:rootbcOpen+term:pubRec+inq6mth:pubRec+verified:roottotalIlLim+region:roottotalBal+roottotalLim:region+openAcc:bcRatio+rootaccOpen24:logIncome+term:rootaccOpen24+delinq2yr:logIncome+amount:pubRec+delinq2yr:region+term:home+term:inq6mth+revolRatio:amount+debtIncRat:verified+rootaccOpen24:revolRatio+rootaccOpen24:rootbcOpen+debtIncRat:rootbcOpen+debtIncRat:bcRatio+debtIncRat:logPayment+roottotalLim:roottotalIlLim+logTotalAcc:roottotalBal+term:roottotalIlLim+logIncome:roottotalIlLim+debtIncRat:home+debtIncRat:logTotalAcc+rootaccOpen24:debtIncRat+term:roottotalLim+logTotalAcc:revolRatio+debtIncRat:revolRatio+roottotalBcLim:bcRatio+rootaccOpen24:verified+debtIncRat:pubRec+logPayment:openAcc+openAcc:amount+inq6mth:roottotalBcLim,family="binomial",data = d_set)
paste('AIC: ',round(extractAIC(second_Order_out_old)[2],0))
d_set <- test # to test the model
d_set$two.old.prob <- predict(second_Order_out_old, d_set, type="response")
accuracy_two_old <- (length(d_set$two.old.prob[c(d_set$two.old.prob >=.5 & d_set$response == 'Good')]) +            length(d_set$two.old.prob[c(d_set$two.old.prob <.5 & d_set$response == 'Bad')])) / length(d_set$two.old.prob)
paste('Accuracy Rate:',round(accuracy_two_old,3))
Sys.time()
print('End')

```

```{r}
length(test$response[test$response=='Good'])/ length(test$response)
```




```{r }
# # Look for 2nd order factors
# print(Sys.time())
# second_Order_out <- step(backward_out,scope = . ~ . ^2 , direction="both", trace = 0)
# 
# test$predict <- predict(second_Order_out, test, type="response")
# accuracy <- (length(test$predict[c(test$predict >=.5 & test$response == 'Good')]) +            length(test$predict[c(test$predict <.5 & test$response == 'Bad')])) / length(test$predict)
# paste('Accuracy Rate:',accuracy)
# 
# print('done')
# print(Sys.time())
# second_Order_out
```



The first one was created by using all dependent variables in the generalized linear model function. 
```{r echo=FALSE}
paste0('Full AIC: ',extractAIC(full_fit)[2])
summary(full_fit)[[1]]
```
The full model has the highest AIC score.

Models two through four were created using the stepwise algorithm and the three directions of forwarding, backward and both.  
```{r echo=FALSE} 
paste0('Forward AIC: ',extractAIC(forward_out)[2])
summary(forward_out)[[1]]

paste0('Backward AIC: ',extractAIC(backward_out)[2])
summary(backward_out)[[1]]

paste0('Both AIC: ',extractAIC(both_out)[2])
summary(both_out)[[1]]
```
These three models were identical to each other.

The final model was created by taking the result of the stepwise model in the forward direction to define all of the one-way interactions and then looking for two-way interactions using the stepwise algorithm again.  
```{r echo=FALSE} 
paste0('2nd Order AIC: ',extractAIC(second_Order_out)[2])
summary(second_Order_out)[[1]]
```
Based on the AIC, this was the best model. 

## Section 6 - Optimizing the Threshold for Accuracy
```{r}
# #load full dataset
# trimmed_loan_data$predict <- predict(second_Order_out, trimmed_loan_data, type="response")
```
#######################################################################
############# Extrapolate based on validation data ####################
#######################################################################
```{r} 
d_set <- test # to test the model
both_out <- glm(formula = response ~ amount + term + rate + home + verified + 
    reason + debtIncRat + delinq2yr + inq6mth + openAcc + revolRatio + 
    bcRatio + logPayment + logIncome + region + logTotalAcc + 
    rootTotalRevBal + rootaccOpen24 + rootbcOpen + roottotalLim + 
    roottotalBal + roottotalBcLim, family = "binomial", data = d_set)



d_set$prob <- predict(both_out, d_set, type="response")
# predprob <- fitted(second_Order_out) # get predicted probabilities
predprob <- d_set$prob # get predicted probabilities
accuracy_table <- numeric()
bad <- numeric()
good <- numeric()
percentBadRej <- numeric()
percentGoodRej <- numeric()

for(i in seq(1,100)){

  threshhold <- i/100  # Set Y=1 when predicted probability exceeds this
  predLoan <- cut(predprob, breaks=c(-Inf, threshhold, Inf),labels=c("Bad", "Good"))  # Y=1 is "Bad"
  d_set$predict <- predLoan
  
  cTab <- table(d_set$response, predLoan) 
  # addmargins(cTab)
  
  p <- sum(diag(cTab)) / sum(cTab)  # compute the proportion of correct classifications
  # print(paste('Proportion correctly predicted = ', p)) 
  accuracy_table[i] <- p
  bad[i] <- length(predLoan[predLoan == 'Bad'])
  good[i] <- length(predLoan[predLoan == 'Good'])

  percentBadRej[i] <- length(d_set$response[d_set$predict == 'Bad' & d_set$response == 'Bad'])/ 
    length( d_set$response[d_set$response == 'Bad'])
  
  percentGoodRej[i] <- length(d_set$response[d_set$predict == 'Bad' & d_set$response == 'Good'])/ 
    length( d_set$response[d_set$response == 'Good'])

}

accuracy_threshold <- which.max(accuracy_table)
accuracy_threshold
accuracy_max <- accuracy_table[which.max(accuracy_table)]
accuracy_max
percent_good <- length(d_set$response[d_set$response =='Good'])/length(d_set$response)
percent_good

```
The Percent Accuracy and Rejected vs Algorithm Score Cutoff graph shows how the approval threshold impacts decision accuracy and what percent of bad and good loans are being rejected.  

```{r echo=FALSE, fig.width=6, fig.height=5}
plot(accuracy_table*100, type='l', col='blue', ylim=c(0,100), xlab='Algorithm Approval Threshold', ylab='Percentage',
     main='Percent Accuracy and Rejected vs. Algorithm Score Cutoff' )
# lines(x=seq(1,100),y=bad/(bad+good)*100,  col='black')
lines(x=seq(1,100),y= percentBadRej* 100,  col='darkmagenta')
lines(x=seq(1,100),y= percentGoodRej* 100,  col='darkgreen')
abline(v=which.max(accuracy_table), col='red')
legend(1,65,title='legend',legend=c('Accuracy %','Max Accuracy','% Bad Loans Rejected','% Good Loans Rejected'), col=c('blue','red','darkmagenta','darkgreen'), lty=1, cex=0.8)
```

`r round(percent_good,2)*100`% of all the loans were good loans and therefore when the cutoff rate is low, the decision accuracy is close to the good loan rate.  

A threshold score of `r accuracy_threshold/100` produced the best accuracy of `r round(accuracy_max,2)*100`%.  

## Section 7 - Optimizing the Threshold for Profit



```{r }
d_set <- test # to test the model
d_set$prob <- predict(both_out, d_set, type="response")
# predprob <- fitted(second_Order_out) # get predicted probabilities
predprob <- d_set$prob # get predicted probabilities
profit_table <- numeric()

for(i in seq(1,100)){
  threshhold <- i/100  # Set Y=1 when predicted probability exceeds this
  # print(threshhold)
  predLoan <- cut(predprob, breaks=c(-Inf, threshhold, Inf), labels=c("Bad", "Good"))  # Y=1 is "Bad"
  d_set$predict <- predLoan
  # print(length(predLoan[which(predLoan == 'Bad')]))
  # print(length(predLoan[which(predLoan == 'Good')]))
  d_set$profit <- 0 
  # No harm no foul, didn't make a bad loan and lost nothing (No need to run, default value is 0)
  # d_set$profit[d_set$predict == 'Bad' & d_set$response == 'Bad'] <- 0
 
  # lost potenial to make a loan, but that money is available for another loan
  # d_set$profit[d_set$predict == 'Bad' & d_set$response == 'Good'] <-  (d_set$amount[d_set$predict == 'Bad' & d_set$response == 'Good'] - d_set$totalPaid[d_set$predict == 'Bad' & d_set$response == 'Good']) 
   
  # Paid - $1000 to put into default and try to collect - 1.1amount
  d_set$profit[d_set$predict == 'Good' & d_set$response == 'Bad'] <- d_set$totalPaid[d_set$predict == 'Good' & d_set$response == 'Bad'] - 500 - d_set$amount[d_set$predict == 'Good' & d_set$response == 'Bad']
  
  # # Made profitable loan
  d_set$profit[d_set$predict == 'Good' & d_set$response == 'Good'] <- d_set$totalPaid[d_set$predict == 'Good' & d_set$response == 'Good'] - d_set$amount[d_set$predict == 'Good' & d_set$response == 'Good']


  p <- sum(d_set$profit)# compute the pro vs lose 
  # print(paste0('i:',i,', p: ',p))
  profit_table[i] <- p
  bad[i] <- length(predLoan[predLoan == 'Bad'])
  good[i] <- length(predLoan[predLoan == 'Good'])
}

no_penalty_threshold <- which.max(profit_table)

pre_model <- (sum(d_set$totalPaid) - sum(d_set$amount) - 500 * length(d_set$amount[d_set$response=='Bad'])) 
pre_model


no_penalty_max <- max(profit_table)
no_penalty_max
# no_penalty_be <- min(which(profit_table > 0))
# no_penalty_be 


perfect_profit <-  (sum(d_set$totalPaid[d_set$response=='Good']) - sum(d_set$amount[d_set$response=='Good']))
perfect_profit

paste('model improvement:', no_penalty_max/pre_model )
paste('ideal model improvement', perfect_profit /no_penalty_max)


# no_penalty_max/pre_model
# no_penalty_max - pre_model
# 
# perfect_profit/no_penalty_max
# perfect_profit - no_penalty_max

true_bad <- d_set$response[which(d_set$response == 'Bad' & predprob < no_penalty_threshold/100)]
true_good <- d_set$response[which(d_set$response == 'Good' & predprob >= no_penalty_threshold/100)] 

which.max(profit_table)

percent_accurate <- (length(true_bad) + length(true_good))/length(d_set$response)
percent_accurate
percent_bad <- length(true_bad)/length(d_set$response[d_set$response=='Bad'])
percent_bad
percent_good <- length(true_good)/length(d_set$response[d_set$response=='Good']) 
percent_good


```
The Profitability vs Algorithm Approval Threshold graph shows how profit is impacted by making bad loans and rejecting good loans. 


```{r echo=FALSE, fig.width=6, fig.height=5}
plot((profit_table)/(max(profit_table))*100, type='l', col='blue', ylim=c(-10 ,100), xlab='Algorithm Approval Threshold', ylab='Percentage', main='Profitability vs Algorithm Approval Threshold' )

lines(x=seq(1,100),y= percentBadRej* 100,  col='darkmagenta')
lines(x=seq(1,100),y= percentGoodRej* 100,  col='darkgreen')
abline(h= pre_model/ no_penalty_max*100, col='black', lty=4)
abline(v=which.max(accuracy_table), col='red')
abline(v=which.max(profit_table), col='green')
legend(1,95,title='legend',legend=c('Current Process Profit','% of Max Profit','Max Accuracy','Max Profit','% Bad Loans Rejected','% Good Loans Rejected'), col=c('black','blue','red','green','darkmagenta','darkgreen'), lty=c(4,1,1,1,1,1), cex=0.8)

```

The graph y-axis is scaled so that the maximum potential profit of $`r round(no_penalty_max/100000 ,2)`M equals 100%. 

The current process profit is $`r round(pre_model/100000,2)`M or `r round(pre_model/no_penalty_max,2)*100`% of the algorithm max profit, and matches the result if we set the threshold to approve 100% of the loans. 

Assumptions: 

- Approving Bad loan cost: Total paid - $500 – loan amount (this is sometimes a profit)

- Rejecting Good loan cost: Lost profit opportunity, the money is available to make another loan. 

As the cutoff point rises above the max profit threshold of `r no_penalty_threshold/100 `, the diminished profit from making fewer loans erodes profitability.

The two histograms show the distribution of both good and bad loans versus algorithm score.

```{r echo=FALSE, fig.width=6, fig.height=4}

par(mfrow=c(1,2), mar=c(5,4,4,2))
hist(predprob[which(trimmed_loan_data$response == 'Bad')], main = 'Histogram of Bad Loans', xlab = 'Algorithm Score', xaxt='n')
axis(side=1, at=seq(0,1, .10), labels=seq(0,1,.1))
abline(v=mean(predprob[which(trimmed_loan_data$response == 'Bad')]), col='red')
hist(predprob[which(trimmed_loan_data$response == 'Good')] , main = 'Histogram of Good Loans', xlab = 'Algorithm Score', xaxt='n' )
axis(side=1, at=seq(0,1, .10), labels=seq(0,1,.1))
abline(v=mean(predprob[which(trimmed_loan_data$response == 'Good')]), col='red')

bad_loan_mean_threshold <- mean(predprob[which(trimmed_loan_data$response == 'Bad')])
good_loan_mean_threshold <- mean(predprob[which(trimmed_loan_data$response == 'Good')])


```


## Section 8 - Results Summary
Where should we place the cutoff and how will that impact the bank? 

To maximize return on loaned money, for the loans in this dataset, we would want to place the automatic cutoff level at `r no_penalty_threshold/100 `. 

For this portfolio of loans, that would represent an accuracy of `r round(percent_accurate,2)*100`% and a total profit of \$`r round(no_penalty_max/100000,2)`M which is an `r round(no_penalty_max/pre_model,2)*100`% increase or an extra $`r round((no_penalty_max - pre_model)/100000)`M in profit over what the back actually realized. 

At the proposed threshold, the percent of bad loans rejected is `r round(percent_bad,2)*100 `%, and the percent of good loans accepted is `r round(percent_good,2)*100 `%. 


While this is a significant improvement there is still room to get better, a perfect model that approve 100% of good loans and rejected 100% of bad loans would outperform this model by `r  round(perfect_profit/no_penalty_max,2)*100`% or $`r  round((perfect_profit - no_penalty_max)/100000,2)`M. 








