{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from time import sleep\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count_to_sleep_at = 17000\n",
    "min_to_sleep = 12\n",
    "tweets_per_request = 100\n",
    "print_progress_row_count = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " def api():\n",
    "        consumer_key = ''\n",
    "        consumer_secret = ''\n",
    "        access_token = ''\n",
    "        access_secret = ''\n",
    "\n",
    "        # Use tweepy.OAuthHandler to create an authentication using the given key and secret\n",
    "        auth = tweepy.OAuthHandler(consumer_key=consumer_key, consumer_secret=consumer_secret)\n",
    "        auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "        # Connect to the Twitter API using the authentication\n",
    "        # Connect to the Twitter API using the authentication\n",
    "        api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, \\\n",
    "                         parser=tweepy.parsers.JSONParser())\n",
    "        return (api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def search_twitter(api, hashtag, max_rows, start_date, end_date):\n",
    "        current_row_count_for_sleep = 0\n",
    "        for each in hashtag:\n",
    "            print('Hashtag: ', each)\n",
    "            again = True\n",
    "            num_needed = max_rows\n",
    "            tweet_list = []\n",
    "            last_id = -1  # id of last tweet seen\n",
    "            while len(tweet_list) < num_needed:\n",
    "                try:\n",
    "                    new_tweets = api.search(q='#%23' + each, tweet_mode='extended', since=start_date,\\\n",
    "                                            until=end_date, lang=\"en\", count = tweets_per_request ,\\\n",
    "                                            max_id=str(last_id - 1))\n",
    "                except tweepy.TweepError as e:\n",
    "                    print(\"Error\", e)\n",
    "                    break\n",
    "                else:\n",
    "                    if not new_tweets:\n",
    "                        print(\"Could not find any more tweets!\")\n",
    "                        break\n",
    "                    tweet_list.extend(new_tweets['statuses'])\n",
    "                    try:\n",
    "                        last_id = new_tweets['statuses'][-1]['id']\n",
    "                    except:\n",
    "                        print('Last ID out of range', len(tweet_list))\n",
    "                        break\n",
    "                    print(\"...%s tweets downloaded so far\" % (len(tweet_list)))\n",
    "                    current_row_count_for_sleep += len(new_tweets['statuses'])\n",
    "                    current_row_count_for_sleep = time_to_sleep(current_row_count_for_sleep)\n",
    "\n",
    "            csv_df = build_df_to_save(tweet_list,each)\n",
    "            write_to_csv(csv_df,each, start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def time_to_sleep(row_count):\n",
    "        if (row_count > row_count_to_sleep_at):\n",
    "            print('Sleep start:', dt.datetime.now())\n",
    "            row_count = 0\n",
    "            for i in range(min_to_sleep):\n",
    "                sleep(60)\n",
    "                print('Slept for', i + 1, 'min(s).')\n",
    "            print('Sleep end:', dt.datetime.now())\n",
    "        return (row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def build_df_to_save (tweet_list, hastag):\n",
    "        # transform the tweepy tweets into a dataframe array that will populate the csv\n",
    "        column_names = ['id', 'hashtags', 'retweet_id', 'user_id', 'user_loc', 'user_time_zone',\n",
    "                        'user_created_at', 'user_desc', 'created_at','retweet_count' ,'text']\n",
    "        nrows = len(tweet_list)\n",
    "        outtweets = pd.DataFrame(index=range(nrows), columns=column_names)\n",
    "        for i in range(nrows):\n",
    "            if 'id' in tweet_list[i]:\n",
    "                value = tweet_list[i]['id']\n",
    "            else:\n",
    "                value = ''\n",
    "            outtweets['id'][i] = value\n",
    "\n",
    "            if 'entities' in tweet_list[i]:\n",
    "                value = []\n",
    "                for tag in tweet_list[i]['entities']['hashtags']:\n",
    "                    value.append(tag['text'])\n",
    "            else:\n",
    "                value = ''\n",
    "            outtweets['hashtags'][i] = value\n",
    "\n",
    "            if 'retweeted_status' in tweet_list[i]:\n",
    "                value = tweet_list[i]['retweeted_status']['id']\n",
    "            else:\n",
    "                value = ''\n",
    "            outtweets['retweet_id'][i] = value\n",
    "\n",
    "            if 'user' in tweet_list[i]:\n",
    "                outtweets['user_id'][i] = tweet_list[i]['user']['id']\n",
    "                outtweets['user_loc'][i] = tweet_list[i]['user']['location']\n",
    "                outtweets['user_time_zone'][i] = tweet_list[i]['user']['time_zone']\n",
    "                outtweets['user_created_at'][i] = tweet_list[i]['user']['created_at']\n",
    "                outtweets['user_desc'][i] = tweet_list[i]['user']['description']\n",
    "\n",
    "            if 'created_at' in tweet_list[i]:\n",
    "                value = tweet_list[i]['created_at']\n",
    "            else:\n",
    "                value = ''\n",
    "            outtweets['created_at'][i] = value\n",
    "\n",
    "            if 'retweet_count' in tweet_list[i]:\n",
    "                value = tweet_list[i]['retweet_count']\n",
    "            else:\n",
    "                value = ''\n",
    "            outtweets['retweet_count'][i] = value\n",
    "\n",
    "\n",
    "            if 'full_text' in tweet_list[i]:\n",
    "                value = tweet_list[i]['full_text'].encode(\"utf-8\")\n",
    "            else:\n",
    "                value = ''\n",
    "            outtweets['text'][i] = value\n",
    "\n",
    "            if(i % print_progress_row_count ==0):\n",
    "                print(i, 'rows have been preped for the csv file')\n",
    "        return(outtweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def write_to_csv(csv_df, hastag, date):\n",
    "        # write the csv\n",
    "        file_name = str(hastag) +'_' + date + '_tweets.csv'\n",
    "        csv_df.to_csv(file_name, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2018-03-25 21:57:38.471567\n"
     ]
    }
   ],
   "source": [
    "print('Start:',dt.datetime.now())\n",
    "#max_tweets = 150000\n",
    "max_tweets = 500\n",
    "hashtag = ['guncontrol','nra']\n",
    "\n",
    "\n",
    "# start_date_vector =['2018-02-24', '2018-02-25','2018-02-26','2018-02-27','2018-02-28','2018-03-01','2018-03-02',\n",
    "#                    '2018-03-03','2018-03-04']\n",
    "# end_date_vector =['2018-02-25', '2018-02-26','2018-02-27','2018-02-28','2018-03-01','2018-03-02','2018-03-03',\n",
    "#                  '2018-03-04', '2018-03-05']\n",
    "\n",
    "start_date_vector =['2018-03-24']\n",
    "end_date_vector =['2018-03-25']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 0\n",
      "Start of  2018-03-24 to 2018-03-25 collection:  2018-03-25 21:57:39.663994\n",
      "Hashtag:  guncontrol\n",
      "...100 tweets downloaded so far\n",
      "...200 tweets downloaded so far\n",
      "...300 tweets downloaded so far\n",
      "...400 tweets downloaded so far\n",
      "...500 tweets downloaded so far\n",
      "0 rows have been preped for the csv file\n",
      "Hashtag:  nra\n",
      "...100 tweets downloaded so far\n",
      "...200 tweets downloaded so far\n",
      "...300 tweets downloaded so far\n",
      "...400 tweets downloaded so far\n",
      "...500 tweets downloaded so far\n",
      "0 rows have been preped for the csv file\n",
      "End of  2018-03-24 to 2018-03-25 collection:  2018-03-25 21:57:51.043567\n",
      "--------------------------------------------------------------\n",
      "Finsished program\n"
     ]
    }
   ],
   "source": [
    "for cycle in range(len(start_date_vector)):\n",
    "    print('Cycle',cycle)\n",
    "    start_date = start_date_vector[cycle]\n",
    "    end_date = end_date_vector[cycle]\n",
    "    print('Start of ',start_date,'to', end_date,'collection: ',dt.datetime.now())\n",
    "    # Get Tweets as list of Json Objects then Pandas DataFrames\n",
    "    twitter_api = api()\n",
    "    search_twitter(twitter_api, hashtag, max_tweets, start_date, end_date)\n",
    "\n",
    "    print('End of ',start_date,'to', end_date,'collection: ',dt.datetime.now())\n",
    "    print('--------------------------------------------------------------')\n",
    "\n",
    "\n",
    "print('Finsished program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
